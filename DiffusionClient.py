import torch
import discord
from discord.ext import commands
import io
import PIL
import concurrent.futures
import asyncio
import gc
import os
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class ImageGenerator(commands.Cog):
    def __init__(self, bot, model_handler):
        self.bot = bot
        self.model_handler = model_handler
        self.lock = asyncio.Lock()

    def generate_with_sdxl_lightning(self, ctx, prompt):
        try:
            pipeline = self.model_handler.loaded_models["image"]["pipeline"]
            seed = int.from_bytes(os.urandom(4), "big")
            logger.info(f"Using seed: {seed}")
            generator = torch.manual_seed(seed)
            image = pipeline(prompt, num_inference_steps=8, guidance_scale=0, generator=generator).images[0]
            return image
        except Exception as e:
            logger.error(f"Error generating image: {e}")
            return None

    @commands.command(aliases=["paint"])
    async def generate_image(self, ctx, *, prompt):
        if "image" not in self.model_handler.loaded_models:
            await ctx.send("No diffusion model loaded. Please load a model using the 'load' command with 'image' as the model type.")
            return

        async with self.lock:
            async with ctx.typing():
                loop = asyncio.get_event_loop()
                with concurrent.futures.ThreadPoolExecutor() as pool:
                    image = await loop.run_in_executor(pool, self.generate_with_sdxl_lightning, ctx, prompt)
                
                if image:
                    with io.BytesIO() as binary_img:
                        image.save(binary_img, 'PNG')
                        binary_img.seek(0)
                        file = discord.File(binary_img, filename='image.png')
                    await ctx.send(file=file)
                    del image
                else:
                    await ctx.send("Unable to generate an image for the given prompt.")
            
            torch.cuda.empty_cache()
            gc.collect()

    @commands.command(name="pipe")
    async def pipe(self, ctx, *, prompt):
        """Generate an image based on the description generated by the chat model."""
        chat_cog = self.bot.get_cog("ChatGenerator")
        if not chat_cog:
            await ctx.send("ChatGenerator cog not loaded. Please load the chat model using the 'load' command with 'chat' as the model type.")
            return

        description = await chat_cog.generate_image_description(ctx, prompt)
        if description:
            await self.generate_image(ctx, prompt=description)
        else:
            await ctx.send("Failed to generate image description.")

async def setup_diffusion_client(bot, model_handler):
    try:
        if bot.get_cog("ImageGenerator"):
            await bot.remove_cog("ImageGenerator")
        await bot.add_cog(ImageGenerator(bot, model_handler))
        logger.info("ImageGenerator cog has been set up successfully.")
    except Exception as e:
        logger.error(f"Error setting up ImageGenerator cog: {e}")
        raise
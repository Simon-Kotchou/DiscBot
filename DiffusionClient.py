import torch
import discord
from discord.ext import commands
import io
import PIL
import concurrent.futures
import asyncio
import gc

class ImageGenerator(commands.Cog):
    def __init__(self, bot, model_handler):
        self.bot = bot
        self.model_handler = model_handler
        self.lock = asyncio.Lock()

    def generate_with_sdxl_turbo(self, ctx, prompt):
        pipeline = self.model_handler.loaded_models["image_fast"]["pipeline"]
        image = pipeline(prompt=prompt, num_inference_steps=1, guidance_scale=0.0, num_images_per_prompt=2).images
        return image

    def generate_with_stable_cascade(self, ctx, prompt):
        pipeline = self.model_handler.loaded_models["image_quality"]["pipeline"]

        # Generate embeddings with the "prior"
        prior_output = pipeline["prior"](
            prompt=prompt,
            height=1024,
            width=1024,
            negative_prompt="",
            guidance_scale=4.0,
            num_inference_steps=30,
            num_images_per_prompt=1
        )

        # Generate the final image with the "decoder"
        decoder_output = pipeline["decoder"](
            image_embeddings=prior_output.image_embeddings,
            prompt=prompt,
            negative_prompt="",
            guidance_scale=0.0,
            output_type="pil",
            num_inference_steps=20,
        ).images

        return decoder_output

    @commands.command(aliases=["paint"])
    async def generate_image(self, ctx, *, prompt):
        """Generate an image based on the given prompt."""
        if "image_fast" not in self.model_handler.loaded_models and "image_quality" not in self.model_handler.loaded_models:
            await ctx.send("No diffusion model loaded. Please load a model using the 'load' command with 'image_fast' or 'image_quality' as the model type.")
            return

        async with self.lock:
            async with ctx.typing():
                loop = asyncio.get_event_loop()
                if "image_fast" in self.model_handler.loaded_models:
                    with concurrent.futures.ThreadPoolExecutor() as pool:
                        images = await loop.run_in_executor(pool, self.generate_with_sdxl_turbo, ctx, prompt)
                elif "image_quality" in self.model_handler.loaded_models:
                    with concurrent.futures.ThreadPoolExecutor() as pool:
                        images = await loop.run_in_executor(pool, self.generate_with_stable_cascade, ctx, prompt)
                else:
                    await ctx.send("No diffusion model loaded. Please load a model using the 'load' command with 'image_fast' or 'image_quality' as the model type.")
                    return

                torch.cuda.empty_cache()
                gc.collect()

                # Check if images is not a list, then make it a list
                if not isinstance(images, list):
                    images = [images]

                # Now images is guaranteed to be a list, so we can iterate
                files = []
                if images:
                    for image in images:
                        with io.BytesIO() as binary_img:
                            image.save(binary_img, 'PNG')
                            binary_img.seek(0)
                            files.append(discord.File(binary_img, filename=f'image_{images.index(image)}.png'))
                    await ctx.send(files=files)
                else:
                    await ctx.send("Unable to generate an image for the given prompt.")

    @commands.command(name="pipe")
    async def pipe(self, ctx, *, prompt):
        """Generate an image based on the description generated by the chat model."""
        chat_cog = self.bot.get_cog("ChatGenerator")
        if not chat_cog:
            await ctx.send("ChatGenerator cog not loaded. Please load the chat model using the 'load' command with 'chat' as the model type.")
            return

        description = await chat_cog.generate_image_description(ctx, prompt)
        if description:
            await self.generate_image(ctx, prompt=description)
        else:
            await ctx.send("Failed to generate image description.")

async def setup_diffusion_client(bot, model_handler):
    if not bot.get_cog("ImageGenerator"):
        await bot.add_cog(ImageGenerator(bot, model_handler))
    else:
        print("ImageGenerator cog has already been added.")